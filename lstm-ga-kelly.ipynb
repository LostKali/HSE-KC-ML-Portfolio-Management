{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3436192b-0051-4fb7-9150-0349b7a29fc2",
   "metadata": {},
   "source": [
    "# Этап 1: Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b157e-4e9b-4b5f-b196-5cbbe644c44a",
   "metadata": {},
   "source": [
    "#### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458641a-a5dd-4d10-9825-d63e772bd97a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Импорт стандартных библиотек\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8fcbe-2a3e-47bf-a3c8-5f84a3f17357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('sp500_historical_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02a6e8-530b-4409-9c13-0d845cf73e49",
   "metadata": {},
   "source": [
    "#### Преобразование столбца даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad233c-0ba6-4815-848f-d9549f10ed95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5e8fd4-2d86-4d35-b239-cd860eae2f74",
   "metadata": {},
   "source": [
    "#### Удаление данных за выходные дни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53168d0-609a-47c8-881d-de31e48280f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data[data['Date'].dt.weekday < 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bbf4b5-3e29-483c-9eea-4880e451bd0c",
   "metadata": {},
   "source": [
    "#### Определение полного диапазона дат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42412c-1295-4673-a6b1-523651cf127c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_date_range = pd.date_range(start=data['Date'].min(), end=data['Date'].max(), freq='B')  # 'B' обозначает бизнес-день"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08be41-6ecd-46fd-b9c2-410ea99d82ea",
   "metadata": {},
   "source": [
    "#### Проверка наличия данных по каждому тикеру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc23a5c0-1335-43a9-84c9-7e323c77d1dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_pivot = data.pivot_table(index='Date', columns='Ticker', values='Adj Close')\n",
    "missing_percent = data_pivot.isnull().mean() * 100\n",
    "tickers_to_remove = missing_percent[missing_percent > 5].index.tolist()\n",
    "clean_data = data[~data['Ticker'].isin(tickers_to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129b7cb-ed8e-413a-95f3-4a3365b2cb96",
   "metadata": {},
   "source": [
    "#### Проверка на дупликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31568333-bc8c-4c79-ae39-9a3e7459a859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_data = clean_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d627aac-121f-4348-906c-d3ad3c70d7e4",
   "metadata": {},
   "source": [
    "#### Обработка подозрительно низкого объема торгов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e62f7e3-6f03-44b8-acb4-f3dcf9793178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "volume_threshold = clean_data['Volume'].quantile(0.01)\n",
    "low_volume_data = clean_data[clean_data['Volume'] <= volume_threshold]\n",
    "low_volume_data.to_csv('low_volume_records.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276abb6-b1e8-49a4-824f-62f774c426da",
   "metadata": {},
   "source": [
    "#### Проверка размерности данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658c43d8-f800-4a27-ac69-a0b4012a7a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_pivot_clean = clean_data.pivot_table(index='Date', columns='Ticker', values='Adj Close')\n",
    "missing_dates_per_ticker = data_pivot_clean.isnull().sum()\n",
    "tickers_with_missing_dates = missing_dates_per_ticker[missing_dates_per_ticker > 0].index.tolist()\n",
    "clean_data = clean_data[~clean_data['Ticker'].isin(tickers_with_missing_dates)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc594fb4-b964-4686-aecd-ddaf647c8e19",
   "metadata": {},
   "source": [
    "#### Сохранение очищенных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc75e58-8b78-40a8-abc7-0c2442c9f43d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_tickers = clean_data['Ticker'].unique()\n",
    "clean_data.to_csv('cleaned_sp500_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b46fee8-272c-4ae9-8055-fe3369aef267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Для разделения данных и предобработки\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Для построения модели LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Для генетического алгоритма\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# Для оценки модели\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Для визуализации\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Дополнительные библиотеки\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717be2dd-25cb-4fcc-9c63-6fc8815fcfac",
   "metadata": {},
   "source": [
    "#### Сбор информации о секторах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb40c9-7126-48e0-ab2b-efbc50b136c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Установка yfinance при необходимости\n",
    "# !pip install yfinance\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "# Получение списка уникальных тикеров\n",
    "tickers = data['Ticker'].unique()\n",
    "\n",
    "# Инициализация словаря для хранения информации о секторах\n",
    "ticker_sectors = {}\n",
    "\n",
    "# Получение информации о секторах для каждого тикера\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        stock_info = yf.Ticker(ticker).info\n",
    "        sector = stock_info.get('sector', 'Unknown')\n",
    "        ticker_sectors[ticker] = sector\n",
    "    except Exception as e:\n",
    "        print(f\"Не удалось получить данные для {ticker}: {e}\")\n",
    "        ticker_sectors[ticker] = 'Unknown'\n",
    "\n",
    "# Создание DataFrame из словаря\n",
    "sectors_df = pd.DataFrame(list(ticker_sectors.items()), columns=['Ticker', 'Sector'])\n",
    "\n",
    "# Объединение информации о секторах с основными данными\n",
    "data = pd.merge(data, sectors_df, on='Ticker', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1014f0-1b08-47cc-968f-e7058f4fe227",
   "metadata": {},
   "source": [
    "#### Загрузка очищенных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a62bdda-ce2c-4733-b073-c0a5e8edcbc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Загрузка очищенных данных\n",
    "data = pd.read_csv('cleaned_sp500_data.csv')\n",
    "\n",
    "# Преобразование столбца 'Date' в формат datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cda131-ab1b-4486-a65f-128a75f67ab9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Этап 2: Построение и оптимизация модели LSTM с помощью GA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1376d-00d1-437b-a132-2c0dd7d60969",
   "metadata": {},
   "source": [
    "#### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0991312c-39ad-4cf3-9914-c1f9173616fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Определение параметров\n",
    "TIME_STEPS = 30  # Длина последовательности для входа в LSTM\n",
    "\n",
    "# Инициализация словарей для хранения результатов\n",
    "models = {}\n",
    "scalers = {}\n",
    "volatility = {}\n",
    "performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6bfc3c-f221-44a1-b83d-d787b51ab2f7",
   "metadata": {},
   "source": [
    "#### Определение функций для подготовки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d7426f2-5de6-43aa-ae12-328fa4abf6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sequences(data, time_steps=TIME_STEPS):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:(i + time_steps)])\n",
    "        y.append(data[i + time_steps])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aebab5c-0b16-4008-b54b-0ec1ab0eb22e",
   "metadata": {},
   "source": [
    "#### Определение функции оценки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e6192f2-2dd4-4caa-98ff-27909e97d21c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def evaluate_model(individual, X_train, y_train, X_val, y_val):\n",
    "    # Распаковка гиперпараметров из индивидуального решения\n",
    "    n_layers = individual[0]\n",
    "    n_neurons = individual[1]\n",
    "    dropout_rate = individual[2]\n",
    "    learning_rate = individual[3]\n",
    "\n",
    "    # Построение модели\n",
    "    K.clear_session()  # Очистка предыдущих моделей из памяти\n",
    "    model = Sequential()\n",
    "\n",
    "    if n_layers == 1:\n",
    "        # Единственный LSTM слой\n",
    "        model.add(LSTM(units=n_neurons, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    else:\n",
    "        # Первый LSTM слой\n",
    "        model.add(LSTM(units=n_neurons, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        # Средние LSTM слои\n",
    "        for _ in range(n_layers - 2):\n",
    "            model.add(LSTM(units=n_neurons, return_sequences=True))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "        # Последний LSTM слой\n",
    "        model.add(LSTM(units=n_neurons, return_sequences=False))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Компиляция модели\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    # Обучение модели\n",
    "    history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "    # Оценка модели на валидационных данных\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "    return val_loss,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a477a53-f2be-48d5-9289-67d48c83eb32",
   "metadata": {},
   "source": [
    "#### Определение процесса генетического алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1967954-53bf-41f1-a992-786c6f00f418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_mutation(individual, indpb):\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() < indpb:\n",
    "            if i == 0:  # n_layers (целое число)\n",
    "                individual[i] = random.randint(1, 2)  # Максимум 2 слоя\n",
    "            elif i == 1:  # n_neurons (целое число)\n",
    "                individual[i] = random.randint(32, 128)  # От 32 до 128 нейронов\n",
    "            elif i == 2:  # dropout_rate (вещественное число)\n",
    "                individual[i] = random.uniform(0.0, 0.3)  # От 0.0 до 0.3\n",
    "            elif i == 3:  # learning_rate (вещественное число)\n",
    "                individual[i] = random.uniform(0.0005, 0.005)  # Уменьшенный диапазон\n",
    "    return individual,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6811865f-f93a-4f6f-b3a4-69ff17be345f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def optimize_model_with_ga(X_train, y_train, X_val, y_val, n_generations, population_size):\n",
    "    # Определение индивидуала и функции приспособленности\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))  # Минимизируем валидационную ошибку\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # Определение атрибутов для каждого гиперпараметра\n",
    "    toolbox.register(\"attr_n_layers\", random.randint, 1, 3)\n",
    "    toolbox.register(\"attr_n_neurons\", random.randint, 32, 256)\n",
    "    toolbox.register(\"attr_dropout_rate\", random.uniform, 0.0, 0.5)\n",
    "    toolbox.register(\"attr_learning_rate\", random.uniform, 0.0001, 0.01)\n",
    "\n",
    "    # Создание индивидуала\n",
    "    toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                     (toolbox.attr_n_layers, toolbox.attr_n_neurons, toolbox.attr_dropout_rate, toolbox.attr_learning_rate), n=1)\n",
    "\n",
    "    # Создание популяции\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    \n",
    "    # Определение функции оценки\n",
    "    def eval_function(individual):\n",
    "        return evaluate_model(individual, X_train, y_train, X_val, y_val)\n",
    "\n",
    "    # Регистрация функций\n",
    "    toolbox.register(\"evaluate\", eval_function)\n",
    "    toolbox.register(\"mate\", tools.cxUniform, indpb=0.5)\n",
    "    toolbox.register(\"mutate\", custom_mutation, indpb=0.2)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    # Инициализация популяции\n",
    "    pop = toolbox.population(n=population_size)\n",
    "\n",
    "    # Запуск генетического алгоритма\n",
    "    hof = tools.HallOfFame(1)  # Отслеживаем лучшее решение\n",
    "\n",
    "    algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=n_generations, halloffame=hof, verbose=False)\n",
    "\n",
    "    best_individual = hof[0]\n",
    "    return best_individual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3a2089-6ea2-4f64-bbe8-1460e4a2a766",
   "metadata": {},
   "source": [
    "#### Обучение модели для каждого тикера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8d4a5-8b97-4195-b7d0-7b3d19287dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель для тикера: MMM уже создана\n",
      "Модель для тикера: AOS уже создана\n",
      "Модель для тикера: ABT уже создана\n",
      "Модель для тикера: ABBV уже создана\n",
      "Модель для тикера: ACN уже создана\n",
      "Модель для тикера: ADBE уже создана\n",
      "Модель для тикера: AMD уже создана\n",
      "Модель для тикера: AES уже создана\n",
      "Модель для тикера: AFL уже создана\n",
      "Модель для тикера: A уже создана\n",
      "Модель для тикера: APD уже создана\n",
      "Модель для тикера: AKAM уже создана\n",
      "Модель для тикера: ALB уже создана\n",
      "Модель для тикера: ARE уже создана\n",
      "Модель для тикера: ALGN уже создана\n",
      "Модель для тикера: ALLE уже создана\n",
      "Модель для тикера: LNT уже создана\n",
      "Модель для тикера: ALL уже создана\n",
      "Модель для тикера: GOOGL уже создана\n",
      "Модель для тикера: GOOG уже создана\n",
      "Модель для тикера: MO уже создана\n",
      "Модель для тикера: AMZN уже создана\n",
      "Модель для тикера: AMCR уже создана\n",
      "Модель для тикера: AEE уже создана\n",
      "Модель для тикера: AEP уже создана\n",
      "Модель для тикера: AXP уже создана\n",
      "Модель для тикера: AIG уже создана\n",
      "Модель для тикера: AMT уже создана\n",
      "Модель для тикера: AWK уже создана\n",
      "Модель для тикера: AMP уже создана\n",
      "Модель для тикера: AME уже создана\n",
      "Модель для тикера: AMGN уже создана\n",
      "Модель для тикера: APH уже создана\n",
      "Модель для тикера: ADI уже создана\n",
      "Модель для тикера: ANSS уже создана\n",
      "Модель для тикера: AON уже создана\n",
      "Модель для тикера: APA уже создана\n",
      "Модель для тикера: AAPL уже создана\n",
      "Модель для тикера: AMAT уже создана\n",
      "Модель для тикера: APTV уже создана\n",
      "Модель для тикера: ACGL уже создана\n",
      "Модель для тикера: ADM уже создана\n",
      "Модель для тикера: ANET уже создана\n",
      "Модель для тикера: AJG уже создана\n",
      "Модель для тикера: AIZ уже создана\n",
      "Модель для тикера: T уже создана\n",
      "Модель для тикера: ATO уже создана\n",
      "Модель для тикера: ADSK уже создана\n",
      "Модель для тикера: ADP уже создана\n",
      "Модель для тикера: AZO уже создана\n",
      "Модель для тикера: AVB уже создана\n",
      "Модель для тикера: AVY уже создана\n",
      "Модель для тикера: AXON уже создана\n",
      "Модель для тикера: BKR уже создана\n",
      "Модель для тикера: BALL уже создана\n",
      "Модель для тикера: BAC уже создана\n",
      "Модель для тикера: BK уже создана\n",
      "Модель для тикера: BBWI уже создана\n",
      "Модель для тикера: BAX уже создана\n",
      "Модель для тикера: BDX уже создана\n",
      "Модель для тикера: BBY уже создана\n",
      "Модель для тикера: TECH уже создана\n",
      "Модель для тикера: BIIB уже создана\n",
      "Модель для тикера: BLK уже создана\n",
      "Модель для тикера: BX уже создана\n",
      "Модель для тикера: BA уже создана\n",
      "Модель для тикера: BKNG уже создана\n",
      "Модель для тикера: BWA уже создана\n",
      "Модель для тикера: BSX уже создана\n",
      "Модель для тикера: BMY уже создана\n",
      "Модель для тикера: AVGO уже создана\n",
      "Модель для тикера: BR уже создана\n",
      "Модель для тикера: BRO уже создана\n",
      "Модель для тикера: BLDR уже создана\n",
      "Модель для тикера: BG уже создана\n",
      "Обработка тикера: BXP\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Обработка тикера: CHRW\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Обработка тикера: CDNS\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x3c1f97f60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x3c1f97f60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Обработка тикера: CZR\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Обработка тикера: CPT\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Обработка тикера: CPB\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Обработка тикера: COF\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Обработка тикера: CAH\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Обработка тикера: KMX\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Обработка тикера: CCL\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Обработка тикера: CTLT\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Обработка тикера: CAT\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Обработка тикера: CBOE\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Обработка тикера: CBRE\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Обработка тикера: CDW\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Обработка тикера: CE\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Обработка тикера: COR\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Обработка тикера: CNC\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Обработка тикера: CNP\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Обработка тикера: CF\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Обработка тикера: CRL\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Обработка тикера: SCHW\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Обработка тикера: CHTR\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Обработка тикера: CVX\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Обработка тикера: CMG\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Обработка тикера: CB\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Обработка тикера: CHD\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Обработка тикера: CI\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Обработка тикера: CINF\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Обработка тикера: CTAS\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Обработка тикера: CSCO\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Обработка тикера: C\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Обработка тикера: CFG\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Обработка тикера: CLX\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Обработка тикера: CME\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Обработка тикера: CMS\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Обработка тикера: KO\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Обработка тикера: CTSH\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Обработка тикера: CL\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Обработка тикера: CMCSA\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Обработка тикера: CAG\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Обработка тикера: COP\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Обработка тикера: ED\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Обработка тикера: STZ\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Обработка тикера: COO\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Обработка тикера: CPRT\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Обработка тикера: GLW\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Обработка тикера: CPAY\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Обработка тикера: CTVA\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Обработка тикера: CSGP\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Обработка тикера: COST\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Обработка тикера: CTRA\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Обработка тикера: CRWD\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Обработка тикера: CCI\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Обработка тикера: CSX\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Обработка тикера: CMI\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Обработка тикера: CVS\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Обработка тикера: DHR\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Обработка тикера: DRI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x335ab0220>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kate/anaconda3/lib/python3.11/weakref.py\", line 369, in remove\n",
      "    def remove(k, selfref=ref(self)):\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Обработка тикера: DVA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x335ab0220>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kate/anaconda3/lib/python3.11/weakref.py\", line 369, in remove\n",
      "    def remove(k, selfref=ref(self)):\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# Создание каталогов для сохранения моделей и графиков\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "if not os.path.exists('plots'):\n",
    "    os.makedirs('plots')\n",
    "\n",
    "# Цикл по каждому тикеру\n",
    "for ticker in tickers:\n",
    "    if not os.path.isfile(f'models/{ticker}_model.keras'):\n",
    "        print(f\"Обработка тикера: {ticker}\")\n",
    "\n",
    "        # Получение данных для тикера\n",
    "        df_ticker = data[data['Ticker'] == ticker].sort_values('Date')\n",
    "\n",
    "        # Используем 'Adj Close' в качестве целевой переменной\n",
    "        close_prices = df_ticker['Adj Close'].values.reshape(-1, 1)\n",
    "\n",
    "        # Проверка достаточности данных\n",
    "        if len(close_prices) <= TIME_STEPS:\n",
    "            print(f\"Недостаточно данных для тикера {ticker}\")\n",
    "            continue\n",
    "\n",
    "        # Масштабирование данных\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_data = scaler.fit_transform(close_prices)\n",
    "        scalers[ticker] = scaler\n",
    "\n",
    "        # Создание последовательностей\n",
    "        X, y = create_sequences(scaled_data)\n",
    "\n",
    "        # Проверка достаточности последовательностей\n",
    "        if len(X) == 0:\n",
    "            print(f\"Недостаточно последовательностей для тикера {ticker}\")\n",
    "            continue\n",
    "\n",
    "        # Разделение данных на обучающую и тестовую выборки (80% на обучение)\n",
    "        split_index = int(0.8 * len(X))\n",
    "        X_train_full, X_test = X[:split_index], X[split_index:]\n",
    "        y_train_full, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "        # Дополнительное разделение обучающих данных на обучение и валидацию (80% на обучение)\n",
    "        val_split_index = int(0.8 * len(X_train_full))\n",
    "        X_train, X_val = X_train_full[:val_split_index], X_train_full[val_split_index:]\n",
    "        y_train, y_val = y_train_full[:val_split_index], y_train_full[val_split_index:]\n",
    "\n",
    "        # Оптимизация модели с помощью GA\n",
    "        best_hyperparams = optimize_model_with_ga(X_train, y_train, X_val, y_val, n_generations=3, population_size=5)\n",
    "\n",
    "        # Извлечение лучших гиперпараметров\n",
    "        n_layers = best_hyperparams[0]\n",
    "        n_neurons = best_hyperparams[1]\n",
    "        dropout_rate = best_hyperparams[2]\n",
    "        learning_rate = best_hyperparams[3]\n",
    "\n",
    "        # Построение финальной модели с лучшими гиперпараметрами\n",
    "        K.clear_session()\n",
    "        model = Sequential()\n",
    "\n",
    "        if n_layers == 1:\n",
    "            # Единственный LSTM слой\n",
    "            model.add(LSTM(units=n_neurons, return_sequences=False, input_shape=(X_train_full.shape[1], X_train_full.shape[2])))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "        else:\n",
    "            # Первый LSTM слой\n",
    "            model.add(LSTM(units=n_neurons, return_sequences=True, input_shape=(X_train_full.shape[1], X_train_full.shape[2])))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "            # Средние LSTM слои\n",
    "            for _ in range(n_layers - 2):\n",
    "                model.add(LSTM(units=n_neurons, return_sequences=True))\n",
    "                model.add(Dropout(dropout_rate))\n",
    "            # Последний LSTM слой\n",
    "            model.add(LSTM(units=n_neurons, return_sequences=False))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "        # Обучение финальной модели на полной обучающей выборке\n",
    "        model.fit(X_train_full, y_train_full, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "        # Оценка модели на тестовых данных\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_inverse = scaler.inverse_transform(y_pred)\n",
    "        y_test_inverse = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        # Расчет метрик оценки\n",
    "        mse = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
    "        mae = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
    "\n",
    "        performance[ticker] = {'MSE': mse, 'MAE': mae}\n",
    "\n",
    "        # Сохранение модели\n",
    "        model.save(f'models/{ticker}_model.keras')\n",
    "        models[ticker] = model\n",
    "\n",
    "        # Визуализация результатов\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(y_test_inverse, label='Реальная цена')\n",
    "        plt.plot(y_pred_inverse, label='Предсказанная цена')\n",
    "        plt.title(f'Предсказание цены для {ticker}')\n",
    "        plt.xlabel('Время')\n",
    "        plt.ylabel('Цена')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'plots/{ticker}_prediction.png')\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(f\"Модель для тикера: {ticker} уже создана\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9295617-4cb2-45ac-a92f-b2c0bde2a5c5",
   "metadata": {},
   "source": [
    "#### Сохранение волатильности и метрик производительности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446ed75-169b-4df0-9f52-83bef5c3cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tickers:\n",
    "    # Расчет доходностей для оценки волатильности\n",
    "    returns = np.log(close_prices[1:] / close_prices[:-1])\n",
    "\n",
    "    # Оценка волатильности (стандартное отклонение доходностей)\n",
    "    volatility_value = np.std(returns)\n",
    "    volatility[ticker] = volatility_value\n",
    "    \n",
    "# Преобразование словаря волатильности в DataFrame\n",
    "volatility_df = pd.DataFrame.from_dict(volatility, orient='index', columns=['Volatility'])\n",
    "volatility_df.to_csv('volatility.csv')\n",
    "\n",
    "# Преобразование словаря производительности в DataFrame\n",
    "performance_df = pd.DataFrame.from_dict(performance, orient='index')\n",
    "performance_df.to_csv('model_performance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a3973-42ad-45b7-9464-1434401fd4f0",
   "metadata": {},
   "source": [
    "#### Организация и документирование результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e4646-0e74-4c40-bc0e-7cf6e25eff54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Создание каталогов при необходимости (если не были созданы ранее)\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "if not os.path.exists('plots'):\n",
    "    os.makedirs('plots')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
